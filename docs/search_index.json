[["introduction.html", "Littalics in wondeRland 1 Introduction", " Littalics in wondeRland Littal Shemer Haim 2022-12-20 1 Introduction “…and what is the use of a book,” thought Alice, “without pictures or conversations?” L. Carroll, Alice’s Adventures in Wonderland But this book is entirely made up of conversation, and for better conversation! It is targeted at HR leaders who practice or aspire to practice People Analytics and intend to do so by having better conversations with data scientists. It offers my experience as a data scientist in discussions with HR leaders I supported on their journey to data-driven organizations. Inspired by the famous book Alice’s Adventure in Wonderland, I gathered many pieces of knowledge that comprise my story. My career was always on the spectrum between people and businesses, and data mediates between these two poles. The use cases I present will show you how. In addition, it will support your learning in my training programs or others, leveraging available datasets that demonstrate how you communicate with a data scientist who happens to use R and RStudio. This book is unique in the domain of People Analytics because it interwinds two well-known conceptual models: “Employee Lifetime Value” and “Analytics Maturity.” Combining both conceptual models enables a thorough understanding of real People Analytics projects. Furthermore, I did not create the simulations to make HR professionals become data scientists but rather to train them to work with data scientists. Therefore, each use case follows similar steps that enable simulating a conversation with a data scientist. “Oh, I’ve had such a curious dream!” said Alice, and she told her sister, as well as she could remember them, all these strange adventures… But our adventure is certainly not a dream! Let’s Start. "],["why-littalics-in-wonderland.html", "1.1 Why Littalics in wondeRland?", " 1.1 Why Littalics in wondeRland? I’ve always been an autodidact. In my +25 years of professional experience, I was an eternal student in many fields: data science, business, technology, consultancy, writing, photography, and more. However, nothing prepared me for the wonder of learning and mastering R. I took my first steps into R programming in 2015 and never quit. I used R to explore various research and methodologies and leveraged it in my consultancy in many creative ways. At this point in my journey, I needed to organize my resources and experiences in R to be more productive, in the projects and workshops I offer. Inspired by the famous book Alice’s Adventure in Wonderland, I gathered many pieces of knowledge that comprise my story and shared them in an open-book format. Alice figured out in the book that “It’s no use going back to yesterday” because she was a different person back then. However, connecting yesterday’s dots brought me to the person I am today, professionally and personally. Returning to my archive was a way to combine my learning dots into solid content that represents me today. The nickname Littalics is another representation of my connected dots. It started as Littalics on Twitter and Facebook. This nickname referred to Analytics, Statistics, Infographics, Ethics, and all other hashtags ended with the suffix ‘ics.’ Eventually, people recognized me off-line with that name. So, Littalics became a domain name and a business identity. The title of this book, Littalics in wondeRland, implies that it is about my journey in the field and my attempt to organize and share the complex body of knowledge that serves me. But before we take the deep dive into R, I’d like to share some context on the domain of expertise in which I used R. "],["why-people-analytics.html", "1.2 Why People Analytics", " 1.2 Why People Analytics The practice of data science is multidisciplinary. It encompasses three general skills – the business domain of expertise, statistical modeling, and programming. Although I used the term Applied Research for most of my career to describe my practice, I experienced the complexity of the data science profession. I have been a consultant in Organizational Research for more than twenty years, long before “People Analytics” emerged. I offered insights into employee experience, performance measures, collaboration, internal customer satisfaction, safety climate, training assessments, etc. To do so, I had to leverage multidisciplinary skills. I considered my practice a career on a spectrum between people and businesses. Data mediates between these two poles because you reveal every action or transaction between people and companies through the data. I had to be an expert in many organizational use cases while analyzing them by the proper methodology and write my analysis as code for reproducibility, which contributed to the profitability of my small business. Therefore, I was a data scientist, and my projects, which served executives in Human resources, were People Analytics projects, i.e., the data science of HR. People Analytics is still a new and growing field. As such, it encounters obstacles and barriers. I think that there is a vicious circle in this field. On the one hand, data literacy among HR professionals is insufficient. On the other hand, there is inadequate open data and use case demos for learning. I developed learning programs in People Analytics to overcome this vicious circle in recent years. I leveraged the handful of open data sets and created learning materials that included domain expertise, research methodology, and code. I incorporated most of these learning materials in this book. Though powerful, the use of R in HR is surprisingly uncommon. So before diving into People Analytics use cases, my choice to use R and my source of inspiration in open-source culture is worth explaining. "],["why-r-and-rstudio.html", "1.3 Why R and Rstudio?", " 1.3 Why R and Rstudio? I have used SPSS and other statistics and analytics software for over twenty years. Then, one day, a former client mentioned that I should have abandoned them and started using R. Curious and confused, I googled it. Then I downloaded R for free and followed recommendations to use RStudio as my programming environment (IDE), again for free. Next, I searched for some additional resources and thought I should give it a try. It took me only a few weeks to discover huge advantages. First, I was happy to discover that my learning was fast and pleasant. My background in statistics and programming made it relatively easy for me to adapt. Furthermore, the endless resources I found online were a significant tailwind. Indeed, I owe much of my progress to R communities and the open-source culture. When I searched for advanced learning programs and more structured learning paths, I could choose from various affordable programs online created by leading universities and professional experts. Secondly, I could do anything I knew and embrace new tricks quickly and completely free. Soon enough, I discovered the vast ecosystem of libraries. I could pick the right ones for any use, from data manipulation to visualization to modeling to reporting. Fortunately, so many brilliant players in the R ecosystem continue contributing as you read those lines, making data science practices more effortless and productive. I must admit that I was lucky to start my R journey when most of the libraries in R that comprise the Tidyverse had been launched already. Finally, R is a statistical programming language created by scientists for scientists. Therefore, many of its solutions also fit many use cases of applied research in a business context. However, in the business environment, most people are non-software experts. Fortunately, internal data clients can use R scripts and projects as is or with their other analytics and reporting tools in their organization. The easy and quick adoption, the flexible and productive usage, and the suit to the business environment encouraged me to combine R with my professional practice and business activity. "],["combining-it-all.html", "1.4 Combining it all", " 1.4 Combining it all This open-book attempts to integrate my personal career experiences with People Analytics use cases and data science practices. To realize this integration, I followed two well-known conceptual models that served me on my journey: the first model is “Employee Lifetime Value,” and the second is “Analytics Maturity.” I came up with the idea to bind these two conceptual models during the workshops I offered in People Analytics. I wanted to enable HR professionals to impact the business by raising the right business questions and leveraging findings and insights derived from people’s data. But HR professionals can support business decision-making only when they communicate those questions to data scientists. I tried to encourage HR professionals to be proactive in conversations with the data scientist who supports their work. Such conversations mediate data science and the business needs in workforce-related analysis and yield impactful storytelling with data. Therefore, I created simulations for them to enable upskilling and reskilling in analytical mindset and critical thinking without becoming data professionals. Each simulation I created included a workforce use case at some point in the employee lifecycle. It also leveraged the use case to demonstrate a practice or methods in data science. Eventually, combining points on the employee lifecycle and data science practices offered a thorough understanding of real People Analytics projects. The main section of this book (Part 3) includes those simulations. It contains eight chapters; each depicts a People Analytics use case and explores a relevant topic in data science. The structure of the eight chapters covers phases of the two conceptual models, “Employee Lifetime Value” and “Analytics Maturity, and essentially interwinds them. From my experience, the best way to develop HR professionals’ data literacy is by using HR data. Therefore, I used open data sources similar to organizational data sets in most learning programs. However, the available open data on HR topics limited my endeavor. Nevertheless, I gathered data resources covering many stages in the employee lifecycle and used them in all analytics maturity levels after anonymizing and randomizing them. The concept of “Employee Lifetime Value” is reviewed in the 1st module and serves as a basis for understanding the analytics processes and data preparation. To proceed with data exploration, visualizations, and hypotheses, I used a dataset of Employee Absenteeism in the 2nd module. Next, testing hypotheses with ANOVA and linear regression is demonstrated in the 3rd module, leveraging the use case of the Gender Pay Gap. I dedicated the two subsequent modules to advanced analytics: In module 4, I used Performance Measures to demonstrate data reduction with factor analysis. In module 5, I predicted Employee Attrition with logistic regression. The following two modules describe semantic analytics: understanding meaning and social context. In module 6, I used Exit Surveys data to analyze text and Categorical data. In module 7, I explored team collaboration with Organization Network Analysis. The last module is an exception. It does not bring a use case or analytics. Instead, I wrapped up with a review of the future of People Analytics, in which such use cases are automated. In the automation phase, new Ethics considerations become crucial. However, understanding the practical foundations of ethics is a learning topic that, in my opinion, should be seeded when starting the People Analytics journey. As mentioned, I did not create the simulations to make HR professionals become data scientists but rather to train them to work with data scientists. Therefore, each chapter that includes a People Analytics use case follows similar steps that enable simulating conversation with a data scientist that supports HR work: use case description, data source, HR briefing, analytics methods review, analysis using R, storytelling with data, and conclusions. The best use of each chapter is to follow these steps to generalize them in a real-life situation where a data scientist is providing an analytics project. This book is not a textbook about R programming. Instead, it focuses on applying R programming in various use cases in People Analytics. Therefore, I did not cover the basics of R programming and focused only on reviewing R code relevant to those use cases. Frankly, I don’t see any point in repeating the best R open books that serve me as frequent learning materials. However, when using various analytics, I referred to other R available books where the reader can expand on the topic. Nevertheless, if you are new to R, I organized all the references for getting started in the next section to ensure that you are ready - or R ready. However, suppose you are a people scientist or analyst; leverage the use cases to expand your tool kit to use R and, if you already do so, to have new ideas about additional use cases and research solutions. "],["r-you-ready-getting-started.html", "2 R you ready? Getting Started", " 2 R you ready? Getting Started My assumption about this book’s readers is that they are either HR professionals or people analysts. HR professionals may want to leverage the use cases of the book to improve their collaboration with data scientists that support their work. If you are amongst this group, please feel free to skip this part or read it to dismiss the mystery of a data scientist’s desktop. People Analysts may want to expand their tool kit with relevant use cases. If you are amongst this group and have short or no experience with R or RStudio, use the following instructions and resources to get ready to start your journey working with these tools. However, remember that there are other environments and programming languages you can choose. The debate about the most suitable tool for data science or People Analytics is beyond the scope of this book. Instead, I offer some orientation for the tools I use. To get started, I believe you need to follow four steps, which I include in this part. You can’t use R and Rstudio without installing them first. Find the resources for Installation in the first section. Then, writing your first lines of code, you must understand how to navigate and find your path. I dedicate the second section to Navigation in this verse and reference resources for R code, R Packages, the IDE, and additional ways to get help. The following section describes the Analytics Process, and its objective is to help you to integrate the use cases in the book. Lastly, I dedicated some paragraphs to reproducibility because I find that professionals in the field lack an understanding of its importance. However, Reproducibility is inherent to all three previous steps. As Alice thought, she was never sure “what I’m going to be, from one minute to another!” but her analytical mindset helped her to understand that she remains herself, even when changing her size to get into her next adventure. "],["instalation.html", "2.1 Instalation", " 2.1 Instalation There are only three things you need to run the code in this book, and you can get them all for free: R, RStudio, and some R packages. First, install R. To download R, go to CRAN (acronyms of the Comprehensive R Archive Network) and follow the instruction. When you finish installation, you’ll have the R programming language on your device. Then, you can program and run the R code independently or in other computer programs, like Rstudio. Secondly, download and install RStudio, the IDE (acronyms of integrated development environment) for R programming. Note that RStudio is not functional without installing R first. In the next section of this part of the book, Navigation, we’ll look at this environment, where you write your R code, run it, and manage your working environment. Lastly, you’ll need to install some R packages, which include functions, datasets, and documentation that expands base R functionality. There are more than 18,000 packages, so which ones do you need? It depends on your domain, analysis, and preferences. In the Navigation section, I review some packages I used in this book. You’ll find additional information in the code within each use case of the book’s third part. Are these installations a one-time hassle? Probably not. R, Rstudio, and R packages frequently update as all things software. A new major R version comes out yearly, with 2-3 minor releases. In addition, R packages are updated from time to time. When you upgrade to a major R version, it requires reinstalling all your packages. RStudio is also updated a few times a year. Please check the colophon in the appendix if you are curious about the versions of R, Rstudio, and the packages I used when I wrote codes for this book. In case you need a comprehensive step-by-step guide for installing R and RStudio, I believe you’ll find the right one within millions of results on Youtube or Google search. For example, many universities have published their tutorials. However, I refer to one resource: Follow the introduction in the book R for Data Science by Hadley Wickham and Garrett Grolemund, which is a valuable resource along your way, whatever it may be. "],["navigation.html", "2.2 Navigation", " 2.2 Navigation If you take your first steps in wondeRland, you must have a few navigation tools. First, you must be acquainted with the basic R syntax. Then, you better understand how to leverage the basic R code with functions of the suitable packages. In addition, you need to organize your data, scripts, outputs, and other resources in your development environment. Lastly, you should always know where to get help when you need it. This section lists all those navigation tools but does not offer a tutorial for any of them. Instead, it refers to some other open books. However, there are endless resources online, including tutorials, articles, and posts on online forums. So when you go on the adventure of writing code, Google is always your best companion. But remember to add “R” to your search query to restrict it to relevant results. 2.2.1 R code I think that this is the boring part of your journey. By itself, programming is not enjoyable for most professionals in the domain of people. However, dirtying my hands in writing code enabled me to tackle some challenges, as you will read in the use cases in the book’s third part. You can screen into the R code to see how I approached them. Your motivation to do so may be better communication with the data scientist that supports your work. Like all programming languages, R has its syntax. But its grammar is relatively easy, and its documentation can help you follow the steps of the data science processes. Therefore, I believe your acquaintance with it will support your interactions with data professionals. In his Handbook of Regression Modeling in People Analytics, Keith McNulty offered an excellent review of R. It covers the basics of R, allowing the inexperienced reader to have some orientation. This review explains all the basics you need: data types and structures in R; the basics of functions and visualizations; and how to handle errors and warnings messages. 2.2.2 R Packages The R programming language is open-source, i.e., people contribute free packages (currently more than 18,000) that make R so powerful, enabling users to do anything in it. Each R package contains functions and documentation for a specific use. It solves a particular problem for the user. Furthermore, all Packages are standardized to allow you to install and use them in your programming environment. To demonstrate installing and loading R packages and to dismiss the confusion about R packages, Ismay and Kim, the authors of the book Statistical Inference via Data Science, used the analogy of apps and mobile phones. R is like a new mobile phone, which has a few features when you use it for the first time. But it doesn’t have everything the user wants or needs. So, R packages are just like apps users can download onto their mobile. Most packages are not installed by default when R and RStudio are installed. So to use the R package for the first time, the user must install it first. Then the user needs to load it each time RSudio is started, just like opening an app on a mobile phone. Similar to apps on mobile phones, downloading and loading R packages is not the end of the story because the user needs to download updates from time to time. 2.2.3 Your IDE When I present screenshots of my work in R-Studio to my workshop participants, I have a single objective: dismissing the mystery of a data scientist’s desktop. If more people become keen users of this IDE, I would consider it a pleasant side effect of my endeavor to enhance communication between HR professionals and date professionals. To explain what I do on R-Studio, I use the analogy of a cake recipe. A good recipe includes a list of ingredients, precise instructions on how to use them, a description of the expected outcomes, and a pleasant and delicious visual display. Of course, R-Studio includes so much more, but let’s stick to the analysis recipe for simplicity. This paragraph is not a tutorial for R-Studio, but rather a general orientation in your navigation. Therefore I mention only some windows in R-Studio, which I picked according to their relevance to the analysis recipe: The environment window includes the ingredients of the recipe: datasets you have opened, new variables you have created, and any other defined objects you make and use during cooking. The script window includes tabs of code in different formats. These code tabs serve as the exact cooking instructions. In addition, they enable you to run, document, and repeat the analysis. Consider the console window a fast oven, where the code runs and outputs are created. The final result may be presented visually as a delicious display in the viewer window. Explore R-Studio’s endless learning resources if you want to learn it from scratch. Otherwise, the analysis recipe is completed and served in the book’s third part. Bon-appetite! 2.2.4 Getting Help Whenever I got stuck using R, Google was my friend. Every error message I googled eventually revealed a resource for resolution because I was not the first to tackle it. However, if you search for help on Google, keep in mind two things: First, you must add “R” to your query to ensure the results are relevant. Secondly, if the search isn’t helpful, it may mean your question is not precise enough, so you should try rephrasing it. Sometimes your Google search results include Stackoverflow questions. The questions and answers on this platform may consist of reproducible examples. In such examples, following the code and data is usually the quick way to resolve your issues. In addition, votes on questions and answers are helpful. Other times Google search results include articles from R-bloggers. This website aggregates hundreds of blogs about R. Some blogs may contain the answers you need. But it is only one resource of the vast community of R users and developers. I recommend following other activities of the R community to broaden your perspective on the problems you face. However, before searching for help outside your IDE, I suggest you try to help yourself with R documentation and help tools. Navigating function documentation is a must because there is no way to remember all parameters and options to twig a function. Essentially it is also hard to remember all the functions in each library. Therefore I recommend getting to know and using RStudio cheatsheets. "],["analytics-process.html", "2.3 Analytics Process", " 2.3 Analytics Process "],["reproducibility.html", "2.4 Reproducibility", " 2.4 Reproducibility "],["people-analytics-methods-and-use-cases.html", "3 People Analytics Methods and Use Cases", " 3 People Analytics Methods and Use Cases I met many HR Leaders and People Analysts over the years, all eager to make an impact in their roles. However, I couldn’t skip noticing how our perspectives differ regarding how you start making an impact. My perspective comes from data science, in which studies aim to discover patterns in data and derive meaningful information to support business decisions. People Analytics, defined as the data science of HR, is all about exploring, inferring, and communicating data patterns to support decisions related to people. To support decisions, always start your analysis with a question in mind. Such a question, handled with the proper analytics process, should lead to actionable insights. If you begin your analytics initiative with data analysis and not a question in mind, there is always a high chance of finding exciting results. However, your results will not affect the business aside from losing valuable managerial attention. A question could be a key concern, a goal, or a challenge for the business. In the case of a People Analytics project, you hypothesize how human performance or behavior impacts that key concern, goal, or challenge. Then you define what you need to measure to test that hypothesis. Having the hypothesis and the measures to test it makes you ready to source the data and start the analytics process. The data in your organization shed light on the business’s current situation and enable an understanding of its factors, directing your intervention and guaranteeing that you discuss your insights in a broader context of the business and workforce markets. However, many HR professionals start elsewhere - with programs, being confident about the organizational development point of view. Even when data is their starting point, it often takes the form of reporting and not exploring. What is the difference between reporting and exploring? To explore data, you must have an analytical mindset. It enables you to analyze information and identify patterns in the data to solve problems. In other words, you use your curiosity by asking the question, “why?”. Dashboards and other reporting methods present different metrics and KPIs and answer the questions: Did we reach our goals? How far are we from achieving our goals? However, by using dashboards, we can’t answer the question, “why?”. So instead, we need to analyze the factors driving those KPIs on our dashboards. I don’t expect HR professionals to become data scientists and run advanced statistics to identify patterns in the data that reveal the factors of KPIs. Still, I’m sure that being a better inner client of data professionals and solutions is essential, and a key to their success is asking, “why?”. It will enable them to tell a straightforward story, impact any topic related to people, track improvement and progress, and indeed contribute and impact the business. Therefore, in the following use cases, I’ll go beyond reporting and dashboarding on the one hand, and I won’t jump to recommended interventions and programs on the other hand. Instead, I will lead the discussion to focus on exploration and demonstrate an analytical mindset that leverages data science in the HR department. The use cases simulate a conversation with a data scientist that supports HR work. Their descriptions include the question in mind, data sources, HR briefing, analytics methods review, analysis using R, storytelling with data, and conclusions. I encourage you to generalize the use cases in real-life situations. "],["employee-lifetime-value.html", "3.1 Employee Lifetime Value", " 3.1 Employee Lifetime Value (Data preparation) "],["employee-absenteeism.html", "3.2 Employee Absenteeism", " 3.2 Employee Absenteeism In this section, we’ll discuss Employee Absenteeism and leverage the topic to practice exploration and hypotheses set by visualization. I based this section on a previous article on my blog: Visualizing Absenteeism At Work. 3.2.1 The use case Employee Absenteeism is a failure to be or remain at work as scheduled or planned. Excessive absenteeism indicates issues and challenges for the organization and within individuals. Absenteeism causes employers productivity loss. There are two main components for this loss: First, absenteeism reduces the outputs of absent employees and the employees who serve as a replacement. Secondly, there are administrative tasks adjusting the workflow. There are implications for individuals too. First, the absent employee may lose pay and experience decreased performance and harm perception. Secondly, co-workers may experience increased workloads that may end in burnout. In addition, clients may suffer lousy service. The organization can evaluate its absenteeism rate in comparison to the sector or country benchmarks. But such a comparison will not point to the absenteeism causes and the proper intervention to reduce it. However, exploring the associations between absenteeism, employee characteristics, and work characteristics are helpful for actionable insights. 3.2.2 Data source I found the data of this use case in the UC Irvine Machine Learning Repository. The database was created at a courier company in Brazil. It includes records of absenteeism from July 2007 to July 2010. Variables in this dataset encompass time and duration of absence, employee background (distance from residence to work, service time, age, education, social drinking, social smoking), and work characteristics (workload, hit targets, disciplinary failure). The structure of this data set is unique. It contains 740 rows and 20 columns. Each record represents an occurrence of absenteeism due to a single reason, measured in hours. Therefore, each employee may have multiple records marked with the same employee’s ID. These records should be summed up. The dataset was used in academic research at the Universidade Nove de Julho – Postgraduate Program in Informatics and Knowledge Management. The data creators are Andrea Martiniano, Ricardo Pinto Ferreira, and Renato Jose Sassi. A special thanks to my colleagues who wrote the open book HR Analytics in R and brought this data set. However, my approach is different. I aim my analysis towards actionable insights, as if my clients are HR leaders, rather than simply exploring the data for analysis, as my colleagues did. Therefore, all variables are considered predictors in creating the visualizations presented in this use case, while absenteeism is the outcome. 3.2.3 HR briefing Suppose you are an HR leader at a courier company. You prepare to advise an intervention plan for the severe issue of driver absenteeism that costs the company its productivity loss. You have records of absent employees for a couple of years. You also have data about employee background in your HRIS. In addition, the business unit provides you with data about the work characteristics of drivers. You ask a data scientist who supports your work to consider those employee background variables and work characteristics variables as predictors of absenteeism. But first, you want to explore the associations by visualizing them. 3.2.4 Analytics methods The focus of this section is visualization. I visualized the data to explore it, mainly to get a glance into the cause of absenteeism in employee characteristics and work attributes. Obviously, an actual project will include additional multivariate statistics and statistical models, but this is beyond the scope of this section. Visualization is a core skill and activity of a data scientist. To excel in visualizing data, understanding statistics and the proper design are necessary. I neglect the explanations of what makes a good visualization, though, letting the charts speak for themselves. However, in most visualizations, I added some remarks to practice critical thinking, which is not only the responsibility of the data scientist but also his sponsors and audience, aka you. In every analysis process, visualization serves two functions: exploring the data and stewarding it to the audience. In this use case, I tried to do both at once. Therefore, I did not settle for sloppy visualization, which is sufficient for the exploration phase, but I took the effort to make the visualization compelling for reporting. Some of the following visualizations I created may seem complicated at first glance. But when I used composed graphical representations of the data, the objective was to explore, with the fewest charts, the association between absenteeism and its two predictor kinds: employee characteristics and work characteristics. Nevertheless, I kept the story proper, ensuring it was appealing, using the right charts, and emphasizing the importance. 3.2.5 Analysis using R 1 - Absenteeism and Employee Background Does absenteeism in the Brazilian courier company relate to its employees’ background? To be more precise, can we point to specific employee groups more prone to be absent? And maybe intervein among these groups? In this part of the analysis, I explored employee background variables, such as age, tenure, body attributes, social behaviors, and family coincidence. I tried to leverage whatever variables I could find in the data. However, People Analysts who work with actual data in their organizations may discover many more relevant variables. In addition, other variables in this dataset are not typical in organizations. 1.1 Employee Age and Tenure How absenteeism, measured in hours, is associated with employee age or tenure? To explore the relationship between these three numerical variables, I suggested a plot that captures the distribution of each variable, scatters each pair of variables and presents the correlation. As clearly shown in Figure 1, absenteeism is not related to age or tenure in the courier company. Notice, however, that age and tenure are correlated in this organization. It may not be the case among other occupations and organizations. Furthermore, the density plots that give you an impression of the shape of the distribution of each variable may also be unique for this case study. dat.fig1 &lt;- dat %&gt;% select(ID, Absenteeism_time_in_hours, Age, Service_time) %&gt;% group_by(ID) %&gt;% summarize(Absenteeism = sum(Absenteeism_time_in_hours), Age = mean(Age), Tenure = mean(Service_time)) %&gt;% select(Absenteeism, Age, Tenure) my_scatter &lt;- function(data,mapping){ ggplot(data=data, mapping=mapping) + geom_point(color=&quot;#3b93a4&quot;) } my_density &lt;- function(data,mapping){ ggplot(data=data,mapping=mapping) + geom_density(alpha=0.65, fill=&quot;#3b93a4&quot;) } fig1 &lt;- ggpairs(dat.fig1, lower=list(continuous=my_scatter), diag=list(continuous=my_density)) fig1 &lt;- fig1 + labs(title=&quot;Figure 1: Absenteeism, Age and Tenure&quot;) fig1 1.2 Employee Body Attributes Does absenteeism associate with employee weight, height, or body mass index? Not at all, according to Figure 2. It may be nonsense to explore this in the context of an organization, and obviously, you don’t collect such data in most occupations. However, since the data set includes those variables, why not explore them? The following exploration is precisely the same as the previous one. Since I already had the code, I could quickly reproduce the visualization. Notice that some employees in this data set are obese. If we find a positive correlation between absenteeism and weight, it doesn’t necessarily mean obesity causes absenteeism. Correlation does not imply causation. The alternative direction of the relation is possible too: People who tend to be absent gain more weight, for some reason. Either way, it’s not the case here. dat.fig2 &lt;- dat %&gt;% select(ID, Absenteeism_time_in_hours, Weight, Height, Body_mass_index) %&gt;% group_by(ID) %&gt;% summarize(Absenteeism = sum(Absenteeism_time_in_hours), Weight = mean(Weight), Height = mean(Height), BMI = mean(Body_mass_index)) %&gt;% select(Absenteeism, Weight, Height, BMI) fig2 &lt;- ggpairs(dat.fig2, lower=list(continuous=my_scatter), diag=list(continuous=my_density)) fig2 &lt;- fig2 + labs(title=&quot;Figure 2: Absenteeism and employee body attributes&quot;) fig2 1.3 Employee Social Behaviors dat.fig3 &lt;- dat %&gt;% select(ID, Absenteeism_time_in_hours, Social_smoker, Social_drinker) %&gt;% group_by(ID) %&gt;% summarize(Absenteeism = sum(Absenteeism_time_in_hours), Smoking = mean(Social_smoker), Drinking = mean(Social_drinker)) %&gt;% select(Absenteeism, Smoking, Drinking) %&gt;% mutate(Smoking = as.factor(recode(Smoking, `0`=&quot;No&quot;, `1`=&quot;Yes&quot;))) %&gt;% mutate(Drinking = as.factor(recode(Drinking, `0`=&quot;No&quot;, `1`=&quot;Yes&quot;))) fig3.1 &lt;- ggplot(dat.fig3, aes(x=Smoking, y=Absenteeism)) + geom_boxplot(aes(fill=Smoking)) + labs(title=&quot;Figure 3: Absenteeism and Smoking&quot;, x=&quot;Smoking&quot;, y=&quot;Absenteeism (hours)&quot;) + theme(legend.position = &quot;none&quot;) + scale_fill_manual(values=c(&quot;#FFFFFF&quot;, &quot;#3b93a4&quot;)) fig3.2 &lt;- ggplot(dat.fig3, aes(x=Drinking, y=Absenteeism)) + geom_boxplot(aes(fill=Drinking)) + labs(title=&quot;Figure 4: Absenteeism and Drinking&quot;, x=&quot;Drinking&quot;, y=&quot;Absenteeism (hours)&quot;) + theme(legend.position = &quot;none&quot;) + scale_fill_manual(values=c(&quot;#FFFFFF&quot;, &quot;#3b93a4&quot;)) grid.arrange(fig3.1, fig3.2, nrow=1) #testing for independency #table(dat.fig3$Smoking, dat.fig3$Drinking) #chisq.test(table(dat.fig3$Smoking, dat.fig3$Drinking)) 1.4 Employee Family Members dat.fig4a &lt;- dat %&gt;% select(ID, Absenteeism_time_in_hours, Son, Pet) %&gt;% group_by(ID) %&gt;% summarize(Absenteeism = sum(Absenteeism_time_in_hours), Children = mean(Son), Pets = mean(Pet)) %&gt;% mutate(Children = recode_factor(Children, `0`=&quot;No kids&quot;, `1`=&quot;Have kids&quot;, `2` = &quot;Have kids&quot;, `3` = &quot;Have kids&quot;, `4` = &quot;Have kids&quot;)) %&gt;% mutate(Pets = recode_factor(Pets, `0`=&quot;No pets&quot;, `1`=&quot;Have pets&quot;, `2` = &quot;Have pets&quot;, `3` = &quot;Have pets&quot;, `4` = &quot;Have pets&quot;, `5` = &quot;Have pets&quot;, `6` = &quot;Have pets&quot;, `7` = &quot;Have pets&quot;, `8` = &quot;Have pets&quot;,)) %&gt;% select(Absenteeism, Children, Pets) fig4a.1 &lt;- ggplot(dat.fig4a, aes(x=Children, y=Absenteeism)) + geom_boxplot(aes(fill=Children)) + labs(title=&quot;Figure 5: Absenteeism and Children&quot;, x=&quot;Children&quot;, y=&quot;Absenteeism (hours)&quot;) + theme(legend.position = &quot;none&quot;) + scale_fill_manual(values=c(&quot;#FFFFFF&quot;, &quot;#3b93a4&quot;)) fig4a.2 &lt;- ggplot(dat.fig4a, aes(x=Pets, y=Absenteeism)) + geom_boxplot(aes(fill=Pets)) + labs(title=&quot;Figure 6: Absenteeism and Pets&quot;, x=&quot;Pets&quot;, y=&quot;Absenteeism (hours)&quot;) + theme(legend.position = &quot;none&quot;) + scale_fill_manual(values=c(&quot;#FFFFFF&quot;, &quot;#3b93a4&quot;)) grid.arrange(fig4a.1, fig4a.2, nrow=1) #testing for independency #table(dat.fig4a$Children, dat.fig4a$Pets) #chisq.test(table(dat.fig4a$Children, dat.fig4a$Pets)) 2 - Absenteeism and Work Characteristics 2.1 Absenteeism, Workload and Commute Distance dat.fig5 &lt;- dat %&gt;% select(ID, Absenteeism_time_in_hours, Work_load_Average_per_day, Distance_from_Residence_to_Work, Education) %&gt;% group_by(ID) %&gt;% summarize(Absenteeism = sum(Absenteeism_time_in_hours), Workload = mean(Work_load_Average_per_day ), Distance = mean(Distance_from_Residence_to_Work), Education = mean(Education)) %&gt;% mutate(Education = recode_factor(Education, `1`=&quot;Low&quot;, `2`=&quot;Mid&quot;, `3` = &quot;High&quot;)) %&gt;% select(Absenteeism, Workload, Distance, Education) fig5.1a &lt;- ggplot(dat.fig5, aes(x=Workload, y=Absenteeism)) + geom_jitter(size=3, color=&quot;#3b93a4&quot;) + geom_smooth(method = lm, se = FALSE, color=&quot;black&quot;) + labs(title=&quot;Figure 7: Absenteeism &amp; Workload&quot;, x=&quot;Workload&quot;, y=&quot;Absenteeism (hours)&quot;) fig5.2a &lt;- ggplot(dat.fig5, aes(x=Distance, y=Absenteeism)) + geom_jitter(size=3, color=&quot;#3b93a4&quot;) + geom_smooth(method = lm, se = FALSE, color=&quot;black&quot;) + labs(title=&quot;Figure 8: Absenteeism &amp; Commute&quot;, x=&quot;Commute Distance&quot;, y=&quot;Absenteeism (hours)&quot;) grid.arrange(fig5.1a, fig5.2a, nrow=1) fig5.1 &lt;- ggplot(dat.fig5, aes(x=Workload, y=Absenteeism, fill=Education, color=Education)) + geom_jitter(size=3) + geom_smooth(method = lm, se = FALSE, aes(colour=Education)) + scale_color_manual(values=c(&quot;#92A9BD&quot;, &quot;#3b93a4&quot;, &quot;#072227&quot;)) + scale_fill_manual(values=c(&quot;#92A9BD&quot;, &quot;#3b93a4&quot;, &quot;#072227&quot;)) + labs(title=&quot;Figure 9: Absenteeism &amp; Workload&quot;, subtitle=&quot;by Education Level&quot;, x=&quot;Workload&quot;, y=&quot;Absenteeism (hours)&quot; ) + theme(legend.position=&quot;top&quot;) fig5.2 &lt;- ggplot(dat.fig5, aes(x=Distance, y=Absenteeism, fill=Education, color=Education)) + geom_jitter(size=3) + geom_smooth(method = lm, se = FALSE, aes(colour=Education)) + scale_color_manual(values=c(&quot;#92A9BD&quot;, &quot;#3b93a4&quot;, &quot;#072227&quot;)) + scale_fill_manual(values=c(&quot;#92A9BD&quot;, &quot;#3b93a4&quot;, &quot;#072227&quot;)) + labs(title=&quot;Figure 10: Absenteeism &amp; Commute&quot;, subtitle=&quot;by Education Level&quot;, x=&quot;Commute Distance&quot;, y=&quot;Absenteeism (hours)&quot; ) + theme(legend.position=&quot;top&quot;) grid.arrange(fig5.1, fig5.2, nrow=1) 2.2 Absenteeism, Hitting targets and Disciplinary failures dat.fig6 &lt;- dat %&gt;% select(ID, Absenteeism_time_in_hours, Hit_target, Disciplinary_failure) %&gt;% group_by(ID) %&gt;% summarize(Absenteeism = sum(Absenteeism_time_in_hours), Success = mean(Hit_target), Indicipline = mean(Disciplinary_failure)) %&gt;% mutate(AbsenteeismDir = ifelse(Indicipline&gt;0.15, -1*Absenteeism, Absenteeism)) %&gt;% select(AbsenteeismDir, Success, Indicipline) fig6.1 &lt;- ggplot(dat.fig6, aes(x=Success, y=AbsenteeismDir)) + geom_segment( aes(x=Success, xend=Success, y=0, yend=AbsenteeismDir), color=&quot;grey&quot;) + geom_point( color=&quot;#3b93a4&quot;, size=2) + theme_light() + theme( panel.grid.major.x = element_blank(), panel.border = element_blank(), axis.ticks.x = element_blank() ) + labs(title=&quot;Figure 11: Absenteeism and Target Hits&quot;, x=&quot;Hit Target&quot;, y=&quot;Absenteeism (hours)&quot;) + annotate(&quot;text&quot;, x = 90.5, y = 400, label = &quot;Disciplined Employees&quot;, colour=&quot;#3b93a4&quot;, size=5) + annotate(&quot;text&quot;, x = 90.5, y = -200, label = &quot;Undisciplined Employees&quot;, colour=&quot;#3b93a4&quot;, size=5) + annotate(&quot;rect&quot;, xmin = 88, xmax = 98, ymin = -400, ymax = 0, alpha = .1) fig6.1 2.3 When Absenteeism Occures? Months and Seasons dat.fig7 &lt;- dat %&gt;% select(Absenteeism_time_in_hours, Month_of_absence) %&gt;% group_by(Month_of_absence) %&gt;% summarize(Absenteeism = sum(Absenteeism_time_in_hours)) fig7 &lt;- ggplot(dat.fig7, aes(x=Month_of_absence, y=Absenteeism)) + geom_line(color=&quot;#3b93a4&quot;) + geom_point(color=&quot;#3b93a4&quot;, size=3)+ scale_x_discrete(name =&quot;Months&quot;, limits=c(&quot;JAN&quot;,&quot;FEB&quot;,&quot;MAR&quot;,&quot;APR&quot;,&quot;MAY&quot;,&quot;JUN&quot;,&quot;JUL&quot;,&quot;AUG&quot;,&quot;SEP&quot;,&quot;OCT&quot;,&quot;NOV&quot;,&quot;DEC&quot;)) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + labs(title=&quot;Figure 12: Monthly Absenteeism&quot;, x=&quot;Month&quot;, y=&quot;Absenteeism (hours)&quot;) dat.fig8 &lt;- dat %&gt;% select(Absenteeism_time_in_hours, Day_of_the_week) %&gt;% group_by(Day_of_the_week) %&gt;% summarize(Absenteeism = sum(Absenteeism_time_in_hours)) fig8 &lt;- ggplot(dat.fig8, aes(x=Day_of_the_week, y=Absenteeism)) + geom_line(color=&quot;#3b93a4&quot;) + geom_point(color=&quot;#3b93a4&quot;, size=3)+ scale_x_discrete(name =&quot;DAYS&quot;, limits=c(&quot;Sun&quot; ,&quot;Mon&quot;,&quot;Tue&quot;,&quot;Wed&quot;,&quot;Thu&quot;,&quot;Fri&quot;, &quot;Sat&quot;)) + ylim(200,1800) + labs(title=&quot;Figure 13: Daily Absenteeism&quot;, x=&quot;Days&quot;, y=&quot;Absenteeism (hours)&quot;) grid.arrange(fig7, fig8, nrow=1) dat.fig9 &lt;- dat %&gt;% select(Absenteeism_time_in_hours, Day_of_the_week, Month_of_absence) %&gt;% group_by(Day_of_the_week, Month_of_absence) %&gt;% summarize(Absenteeism = sum(Absenteeism_time_in_hours)) fig9 &lt;- ggplot(dat.fig9, aes(x=Day_of_the_week, y=Month_of_absence, fill=Absenteeism)) + geom_tile() + scale_fill_gradient(low = &quot;#EDEDED&quot;, high = &quot;#3b93a4&quot;) + #theme_bw() + theme_light() + theme( panel.grid.major.x = element_blank(), panel.border = element_blank(), axis.ticks.x = element_blank() ) + scale_y_discrete(name =&quot;Months&quot;, limits=c(&quot;JAN&quot;,&quot;FEB&quot;,&quot;MAR&quot;,&quot;APR&quot;,&quot;MAY&quot;,&quot;JUN&quot;,&quot;JUL&quot;,&quot;AUG&quot;,&quot;SEP&quot;,&quot;OCT&quot;,&quot;NOV&quot;,&quot;DEC&quot;)) + scale_x_discrete(name =&quot;Days&quot;, limits=c(&quot;Sun&quot; ,&quot;Mon&quot;,&quot;Tue&quot;,&quot;Wed&quot;,&quot;Thu&quot;,&quot;Fri&quot;, &quot;Sat&quot;)) + labs(title=&quot;Figure 14: Absenteeism by Days and Monthes - Heat Map&quot;) + geom_text(aes(label = Absenteeism), color = &quot;white&quot;, size = 4) fig9 3.2.6 Storytelling with data 3.2.7 Conclusions "],["gender-pay-gap.html", "3.3 Gender Pay Gap", " 3.3 Gender Pay Gap In this section, we’ll discuss Gender Pay Gap and leverage the topic to practice hypotheses setting and testing by ANOVA and Linear Regression. I based this section on three articles published on my blog: (1) Gender Pay Gap: Practice People Analytics With Open Data, (2) Finding Hidden Patterns In Gender Pay Gap Data, and (3) Gender Pay Gap: More Hidden Patterns. 3.3.1 The use case The gender pay gap exists despite regulation, policies, hype, and preoccupation with the subject. Women still earn less than men in many countries, sectors, and roles. Moreover, the gap has been persistent over the years. There is no single cause for the gender pay gap. The reasons include: Gender-biased industries and roles in which female-dominated jobs often have lower wages and in which women are under-represented in high-income jobs; Bias and discrimination in recruitment, promotion, and compensation decisions; Disproportionate share of unpaid domestic work and care that women tend to handle more; Women’s careers are impacted by more time spent out of work as parents, and suffer more from the lack work flexibility in senior roles. To address the gender pay gap, employers may intervene in different ways. First, they need to analyze their pay data and processes. Then, after understanding the source of bias, they can take action and review the impact over time. Closing the gender pay gap is essential for everybody, not only women. Employers who take action to close the pay gap may benefit from higher retention, improved employee engagement, higher levels of productivity, and lower legal risks. In addition, the entire society may benefit as women increase their bargaining power and independence and decrease the chance of poverty later in life. 3.3.2 Data source My source and inspiration for this case study was a dataset of employee salaries in a municipal authority organization, Montgomery County, Maryland, in 2017. For public transparency, this organization shares its dataset. The employee salaries in 2017 contained almost 10 thousand records and included annual salary information and some demographics and background variables (gender, tenure, role, department, full and part-time position). However, for our educational purpose, I anonymized and randomized it, so, from the following findings, it would be impossible to point to individuals or even recognize the organization. But I guarantee that the dataset I used is realistic. Before we proceed to the HR briefing, there are some notes worth mentioning about this dataset. First, it includes only binary gender categories, restricting the analysis to comparing only men vs. women. However, some organizations use more gender categories nowadays. Secondly, in many organizations, the data about employees’ occupation, seniority, gender, mode of employment, and salary details are likely to be stored in more than one platform, for example, the HR platform and payroll software. Moreover, there may be more than one payroll system in global organizations, and it is necessary to merge the data and manipulate it for a unified currency. If your platforms are not integrated, you must incorporate data from different sources for your project and make sure that your process is reproducible. Lastly, If you’d look at the CSV file for this demo, you’d immediately see - It is tidy data! It assigns each row to an employee and each column to a variable. Each cell represents only one value specific to one employee and one variable. Of course, the data you pull out for analysis may not be so neat in real-life situations. There will be duplicate records, missing entries, typos, and more. Your data scientist will need to clean and prepare the data for the project. This work may be tedious, but the systematic errors you may find will help you establish better maintenance practices and improve the data over time. It would be helpful beyond best practice because more and more countries regulate the gender pay gap. 3.3.3 HR briefing Suppose you are an HR leader in a municipal authority organization. Like many public organizations, your employer is subjected to strict regulations regarding equal pay. However, only going beyond the basic comparison between men and women will enable you to spot patterns of bias and reach some actionable insights. Therefore, you decide to shed light on the still-existing pay gap, understand its factors, direct your intervention, and guarantee that you discuss insights in a broader context of the business and workforce markets. In other words, you decide to go beyond reporting and go the extra mile to explore the data. What is the difference between reporting and exploring? To explore data, you must have an analytical mindset. It enables you to analyze information and identify patterns in the data to solve problems. So you use your curiosity by asking the question, “why?”. It will enable you to tell a straightforward story, impact any topic related to people, track improvement and progress, and certainly contribute to closing the gender pay gap. You may already have dashboards that enable you to present different metrics and KPIs and answer the questions: Did we reach our goals? How far are we from achieving our goals? However, by using dashboards, you can’t answer the question: Why? Instead, you need to analyze the factors that drive those KPIs presented on your dashboards. Therefore, you will explore the data beyond finding differences between men and women in compensation and explore how those differences occurred, implying what you should do about it. You’ll reach actionable insights by actively working with your data scientist. When you ask “why,” the data scientist will provide answers based on the data. 3.3.4 Analytics methods 3.3.5 Analysis using R par(mfrow = c(2, 2)) hist(Employees$Annual.Salary[Employees$Gender==&quot;F&quot;], col=&quot;orange&quot;, xlim=c(0,300000), breaks = 50, freq = FALSE, xlab = NULL, main = &quot;Current Annual Salary - Women, Avg 73K&quot;) curve(dnorm (x, mean = mean(Employees$Annual.Salary), sd = sd(Employees$Annual.Salary)), add = TRUE) boxplot(Employees$Annual.Salary[Employees$Gender==&quot;F&quot;], horizontal = TRUE, col=&quot;orange&quot;, ylim = c(0,300000)) hist(Employees$Annual.Salary[Employees$Gender==&quot;M&quot;], col=&quot;lightblue&quot;, xlim=c(0,300000), breaks = 50, freq = FALSE, xlab = NULL, main = &quot;Current Annual Salary - Men, Avg 77K&quot;) curve(dnorm (x, mean = mean(Employees$Annual.Salary), sd = sd(Employees$Annual.Salary)), add = TRUE) boxplot(Employees$Annual.Salary[Employees$Gender==&quot;M&quot;], horizontal = TRUE, col=&quot;lightblue&quot;, ylim = c(0,300000)) par(mfrow = c(2, 2)) hist(EmployeesDiverse$Annual.Salary[EmployeesDiverse$Gender==&quot;F&quot;], col=&quot;orange&quot;, xlim=c(0,300000), breaks = 50, freq = FALSE, xlab = NULL, main = &quot;Current Annual Salary - Women, Avg 72K&quot;) curve(dnorm (x, mean = mean(EmployeesDiverse$Annual.Salary), sd = sd(EmployeesDiverse$Annual.Salary)), add = TRUE) boxplot(EmployeesDiverse$Annual.Salary[EmployeesDiverse$Gender==&quot;F&quot;], horizontal = TRUE, col=&quot;orange&quot;, ylim = c(0,300000)) hist(EmployeesDiverse$Annual.Salary[EmployeesDiverse$Gender==&quot;M&quot;], col=&quot;lightblue&quot;, xlim=c(0,300000), breaks = 50, freq = FALSE, xlab = NULL, main = &quot;Current Annual Salary - Men, Avg 78K&quot;) curve(dnorm (x, mean = mean(EmployeesDiverse$Annual.Salary), sd = sd(EmployeesDiverse$Annual.Salary)), add = TRUE) boxplot(EmployeesDiverse$Annual.Salary[EmployeesDiverse$Gender==&quot;M&quot;], horizontal = TRUE, col=&quot;lightblue&quot;, ylim = c(0,300000)) interaction2 &lt;- aggregate(Employees$Annual.Salary, by=list(Employees$Gender, Employees$Tenure), FUN=mean, na.rm=TRUE) colnames(interaction2) &lt;-c(&quot;Gender&quot;, &quot;Tenure&quot;, &quot;Salary&quot;) interaction2plot &lt;- ggplot(data=interaction2, mapping=aes(x=Tenure, y=Salary, color=Gender)) + geom_point(size = 5) + geom_line(aes(group = Gender), size=1) + scale_y_continuous(name=&quot;Annual Salary&quot;, limits=c(30000,100000), labels = scales::comma) + scale_color_manual(values=c(&quot;orange&quot;, &quot;skyblue&quot;)) + theme_bw() interaction2plot interaction2diverse &lt;- aggregate(EmployeesDiverse$Annual.Salary, by=list(EmployeesDiverse$Gender, EmployeesDiverse$Tenure), FUN=mean, na.rm=TRUE) colnames(interaction2diverse) &lt;-c(&quot;Gender&quot;, &quot;Tenure&quot;, &quot;Salary&quot;) interaction2plotdiverse &lt;- ggplot(data=interaction2diverse, mapping=aes(x=Tenure, y=Salary, color=Gender)) + geom_point(size = 5) + geom_line(aes(group = Gender), size=1) + scale_y_continuous(name=&quot;Annual Salary&quot;, limits=c(30000,100000), labels = scales::comma) + scale_color_manual(values=c(&quot;orange&quot;, &quot;skyblue&quot;)) + theme_bw() interaction2plotdiverse reg2plotdiverse &lt;- EmployeesDiverse %&gt;% ggplot(aes(Tenure.Years, Annual.Salary, color=Gender)) + geom_point(alpha = 0.5) + geom_smooth(method = lm, se = FALSE, aes(colour=Gender), size=1.75) + ylim(0,200000) + scale_color_manual(values=c(&quot;orange&quot;, &quot;skyblue&quot;)) + theme_bw() reg2plotdiverse reg2Aplotdiverse &lt;- EmployeesDiverse %&gt;% ggplot(aes(Tenure.Years, Annual.Salary, color=Gender, size=Assignment)) + #Part-time dots enlarged geom_point(alpha = 0.3) + geom_smooth(method = lm, se = FALSE, aes(colour=Gender), size=1.75) + ylim(0,200000) + scale_color_manual(values=c(&quot;orange&quot;, &quot;skyblue&quot;)) + theme_bw() reg2Aplotdiverse reg2Bplotdiverse &lt;- EmployeesDiverse %&gt;% ggplot(aes(Tenure.Years, Annual.Salary, color=Gender, size=Assignment)) + geom_point(alpha = 0.3) + geom_smooth(method = lm, se = FALSE, aes(colour=Gender, linetype=Assignment), size=1.75) + #Part-time line separated ylim(0,200000) + scale_color_manual(values=c(&quot;orange&quot;, &quot;skyblue&quot;)) + theme_bw() reg2Bplotdiverse 3.3.6 Storytelling with data 3.3.7 Conclusions "],["performance-measures.html", "3.4 4 Performance Measures", " 3.4 4 Performance Measures (Levels of measures, Factor Analysis) "],["employee-attrition.html", "3.5 Employee Attrition", " 3.5 Employee Attrition (Predictive analytics, Logistic Regression) "],["exit-surveys.html", "3.6 Exit Surveys", " 3.6 Exit Surveys (Text and Categorical data) "],["teams-and-collaboration.html", "3.7 Teams and collaboration", " 3.7 Teams and collaboration (Organization Network Analysis) "],["the-future-of-people-analytics.html", "3.8 The future of People Analytics", " 3.8 The future of People Analytics (Ethics considerations) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
